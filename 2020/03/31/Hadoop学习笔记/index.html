<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=0"><meta name="description" content="Hadoop学习笔记 [ 张文轩 ] "><meta name="theme-color" content="#ebc65a"><title>Hadoop学习笔记 [ 张文轩 ] </title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css"><script src="https://cdn.bootcss.com/highlight.js/9.6.0/highlight.min.js" defer></script><script src="/js/paper.js" defer></script><script src="https://www.googletagmanager.com/gtag/js?id=xx-xxxxxxx-xx" async></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'xx-xxxxxxx-xx');</script><link rel="stylesheet" href="/css/tocbot.css"><script src="/js/tocbot.js" defer></script><script>window.addEventListener('DOMContentLoaded', () => {
  tocbot.init({
    // Where to render the table of contents.
    tocSelector: '.toc__content',
    // Where to grab the headings to build the table of contents.
    contentSelector: '.article__content',
    // Which headings to grab inside of the contentSelector element.
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    // For headings inside relative or absolute positioned containers within content.
    hasInnerContainers: true,
    orderedList: false,
    collapseDepth: 2,
  });
})</script><link rel="preload" href="https://cdn.bootcss.com/highlight.js/9.6.0/styles/github.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.6.0/styles/github.min.css"><link rel="preload" href="https://fonts.googleapis.com/css?family=Abril+Fatface&amp;display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface&amp;display=swap"></head><body><div class="mask-border"></div><div class="head"><div class="head__inner"><h1><a href="/">张文轩</a></h1><p></p></div></div><div class="paper-container"><div class="main"><div class="location-bar"><div class="line-1"><div class="horizontal-line" style="height: 3px"></div></div><div class="line-2"><div class="horizontal-line" style="height: 1px"></div></div><p class="text">Hadoop学习笔记</p><div class="switch-button"><input class="container_toggle" type="checkbox" id="switch" name="mode"><label for="switch">Toggle</label></div><div class="line-3"><div class="horizontal-line" style="height: 1px"></div></div></div><div class="main__2-col"><article class="post-view__article"><div class="article__infomation"><div class="posts-item"><h2 class="posts-item__title"><a href="">Hadoop学习笔记</a></h2><span class="post__date">2020-03-31</span></div></div><div class="article__content"><h1 id="Hadoop简介"><a href="#Hadoop简介" class="headerlink" title="Hadoop简介"></a>Hadoop简介</h1><p>Hadoop可运行于一般的商用服务器上，具有高容错、高可靠性、高扩展性等特点。特别适合写一次，读多次的场景。</p>
<center class="half"><br><img src="/2020/03/31/Hadoop学习笔记/Hadoop架构.png"><br></center>

<ul>
<li>HDFS：Hadoop Distributed File System 分布式文件存储系统</li>
<li>YARN：分布式资源管理</li>
<li>MapReduce：分布式计算</li>
<li>Others：利用YARN的资源管理功能实现其他的数据处理方式</li>
</ul>
<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p>Hadoop Distributed File System，分布式文件系统</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><center class="half"><br><img src="/2020/03/31/Hadoop学习笔记/HDFS架构.png"><br></center>

<ul>
<li><p>Block数据块</p>
<ol>
<li>基本存储单位，一般大小为64M。</li>
<li>大文件会被拆分成一个个块，存储于不同的机器。如果文件小于Block大小，实际的空间为其文件的大小。</li>
<li>基本的读写单位，类似于磁盘的页，每次都是读写一个块。</li>
<li>每个块都会被复制到多台机器，默认复制三份。</li>
</ol>
</li>
<li><p>NameNode</p>
<ol>
<li>存储文件的metadata，运行时所有数据都保存到内存，整个HDFS可存储的文件数受限于NameNode的内存大小。</li>
<li>一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果是大量的小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件的速度。因此Hadoop建议存储大文件。</li>
<li>数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode中与DataNode相关的信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建）。</li>
<li>NameNode失效则整个HDFS都失效了，所以要保证NameNode的可用性。</li>
</ol>
</li>
<li><p>Secondary NameNode</p>
<p>定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手工将其设置成主机。</p>
</li>
<li><p>DataNode</p>
<ol>
<li>保存具体的Block数据。</li>
<li>负责数据的读写操作和复制操作。</li>
<li>DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息。</li>
<li>DataNode之间会进行通信，复制数据块，保证数据的冗余性。</li>
</ol>
</li>
</ul>
<h2 id="写文件"><a href="#写文件" class="headerlink" title="写文件"></a>写文件</h2><center class="half"><br><img src="/2020/03/31/Hadoop学习笔记/HDFS写文件.png"><br></center>

<ol>
<li><p>客户端将文件写入本地磁盘的HDFS Client文件中</p>
</li>
<li><p>当临时文件大小达到一个block大小时，HDFS client通知NameNode，申请写入文件</p>
</li>
<li><p>NameNode在HDFS的文件系统中创建一个文件，并把该block id和要写入的DataNode的列表返回给客户端</p>
</li>
<li><p>客户端收到这些信息后，将临时文件写入DataNodes</p>
</li>
</ol>
<ul>
<li>4.1 客户端将文件内容写入第一个DataNode（一般以4kb为单位进行传输）</li>
<li>4.2 第一个DataNode接收后，将数据写入本地磁盘，同时也传输给第二个DataNode</li>
<li>4.3 依此类推到最后一个DataNode，数据在DataNode之间是通过pipeline的方式进行复制的</li>
<li>4.4 后面的DataNode接收完数据后，都会发送一个确认给前一个DataNode，最终第一个DataNode返回确认给客户端</li>
<li>4.5 当客户端接收到整个block的确认后，会向NameNode发送一个最终的确认信息</li>
<li>4.6 如果写入某个DataNode失败，数据会继续写入其他的DataNode。然后NameNode会找另外一个好的DataNode继续复制，以保证冗余性</li>
<li>4.7 每个block都会有一个校验码，并存放到独立的文件中，以便读的时候来验证其完整性</li>
</ul>
<ol start="5">
<li>文件写完后（客户端关闭），NameNode提交文件（这时文件才可见，如果提交前，NameNode垮掉，那文件也就丢失了。fsync：只保证数据的信息写到NameNode上，但并不保证数据已经被写到DataNode中）</li>
</ol>
<h2 id="读文件"><a href="#读文件" class="headerlink" title="读文件"></a>读文件</h2><center class="half"><br><img src="/2020/03/31/Hadoop学习笔记/HDFS读文件.png"><br></center>

<ol>
<li>客户端向NameNode发送读取请求</li>
<li>NameNode返回文件的所有block和这些block所在的DataNodes（包括复制节点）</li>
<li>客户端直接从DataNode中读取数据，如果该DataNode读取失败（DataNode失效或校验码不对），则从复制节点中读取（如果读取的数据就在本机，则直接读取，否则通过网络读取）</li>
</ol>
<h2 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h2><ol>
<li><p>DataNode可以失效</p>
<p>DataNode会定时发送心跳到NameNode。如果一段时间内NameNode没有收到DataNode的心跳消息，则认为其失效。此时NameNode就会将该节点的数据（从该节点的复制节点中获取）复制到另外的DataNode中。</p>
</li>
<li><p>数据可以毁坏</p>
<p>无论是写入时还是硬盘本身的问题，只要数据有问题（读取时通过校验码来检测），都可以通过其他的复制节点读取，同时还会再复制一份到健康的节点中。</p>
</li>
<li><p>NameNode不可靠</p>
</li>
</ol>
<h1 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h1><h2 id="旧MapReduce架构"><a href="#旧MapReduce架构" class="headerlink" title="旧MapReduce架构"></a>旧MapReduce架构</h2><center class="half"><br><img src="/2020/03/31/Hadoop学习笔记/旧MapReduce架构.jpg"><br></center>

<ul>
<li>JobTracker：作业生命周期管理（调度作业任务、跟踪进度、为任务提供容错）。</li>
<li>TaskTracker：加载或关闭任务，定时报告任务状态。</li>
</ul>
<p><em>存在的问题：</em></p>
<ol>
<li>obTracker是MapReduce的集中处理点，存在单点故障。</li>
<li>JobTracker完成了太多的任务，造成了过多的资源消耗，当MapReduce job 非常多的时候，会造成很大的内存开销。这也是业界普遍总结出老Hadoop的MapReduce只能支持4000 节点主机的上限。</li>
<li>在TaskTracker端，以map/reduce task的数目作为资源的表示过于简单，没有考虑到cpu/ 内存的占用情况，如果两个大内存消耗的task被调度到了一块，很容易出现OOM（OutOfMemory）。</li>
<li>在TaskTracker端，把资源强制划分为map task slot和reduce task slot, 如果当系统中只有map task或者只有reduce task的时候，会造成资源的浪费，也就集群资源利用的问题。</li>
</ol>
<h2 id="YARN架构"><a href="#YARN架构" class="headerlink" title="YARN架构"></a>YARN架构</h2><center class="half"><br><img src="/2020/03/31/Hadoop学习笔记/YARN架构1.jpg"><br><img src="/2020/03/31/Hadoop学习笔记/YARN架构2.jpg"><br></center>

<p>YARN就是将JobTracker的职责进行拆分，将资源管理和任务调度监控拆分成独立#x7ACB;的进程：一个全局的资源管理和一个每个作业的管理（ApplicationMaster） ResourceManager和NodeManager提供了计算资源的分配和管理，而ApplicationMaster则完成应用程序的运行</p>
<ul>
<li><strong>ResourceManager:</strong> 全局资源管理和任务调度</li>
<li><strong>NodeManager:</strong> 单个节点的资源管理和监控</li>
<li><strong>ApplicationMaster:</strong> 单个作业的资源管理和任务监控</li>
<li><strong>Container:</strong> 资源申请的单位和任务运行的容器</li>
</ul>
<h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><p>一种分布式的计算方式指定一个Map（映#x5C04;）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。</p>
<p><em>详细流程</em></p>
<center class="half"><br><img src="/2020/03/31/Hadoop学习笔记/mapreduce-process.png"><br></center>

</div></article><div class="post-view__sidebar"><div class="sidebar"><div class="tocbot"><h2>Toc</h2><div class="toc__content"></div></div><h2>Archives</h2><div class="sidebar__archives"><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/">2018</a></li></ul></div><h2>Categories</h2><div class="sidebar__categories"></div><h2>Tags</h2><div class="sidebar__tags"><ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mac/">Mac</a></li></ul></div></div></div></div><div class="horizontal-line" style="height: 1px"></div><div class="main__bottom"><div class="pre-next"><a class="pre-button" href="/2020/03/31/Spark中的RDD/">Spark中的RDD</a><a class="next-button" href="/2020/02/27/Https和Http的区别/">Https和Http的区别</a></div></div></div></div><div class="footer"><span>©️2019-2020 Designed By&nbsp;<strong><a href="https://github.com/random-yang">RandomYang</a></strong> Powered By&nbsp;</span><strong><a href="https://hexo.io">hexo</a></strong></div><div class="darkmode-mask" id="darkmode-mask"></div><div class="sidebar__button"></div></body></html>